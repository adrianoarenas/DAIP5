{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA = pd.read_csv('Company A - Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a function to do some cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_data(x):\n",
    "    x.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    x = x.replace(r'^\\s*$', 0, regex=True)\n",
    "    x['TotalCharges'] = pd.to_numeric(x['TotalCharges'])\n",
    "    \n",
    "    x.gender.replace(('Male', 'Female'), (1, 0), inplace=True)\n",
    "    x.Partner.replace(('Yes', 'No'), (1, 0), inplace=True)\n",
    "    x.Dependents.replace(('Yes', 'No'), (1, 0), inplace=True)\n",
    "    x.PhoneService.replace(('Yes', 'No'), (1, 0), inplace=True)\n",
    "    x.PaperlessBilling.replace(('Yes', 'No'), (1, 0), inplace=True)\n",
    "    x.Churn.replace(('Yes', 'No'), (1, 0), inplace=True)\n",
    "    x.dropna(axis=0, inplace=True)\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit our data to the function we created above, mostly replacing binary categories for 1s and 0s for ease of modelling\n",
    "\n",
    "In the next step we drop TotalCharges as its directly correlated to tenure*MonthlyCharges and CustomerID as it doesnt really add much\n",
    "\n",
    "We also divide our data into X and y datasets for the modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA = fix_data(dfA)\n",
    "\n",
    "X = dfA.drop(['Churn','customerID','TotalCharges'], axis=1)\n",
    "y = dfA['Churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot encoding the rest of our category variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(categories='auto', drop= 'first')\n",
    "feature_arr = ohe.fit_transform(X[['InternetService','OnlineSecurity', 'OnlineBackup',\n",
    "                                  'DeviceProtection', 'TechSupport','StreamingTV','StreamingMovies',\n",
    "                                   'Contract','PaymentMethod','MultipleLines']]).toarray()\n",
    "\n",
    "features = pd.DataFrame(feature_arr)\n",
    "\n",
    "X = pd.concat([X, features], axis=1)\n",
    "X.drop(['InternetService','OnlineSecurity', 'OnlineBackup',\n",
    "        'DeviceProtection', 'TechSupport','StreamingTV','StreamingMovies',\n",
    "        'Contract','PaymentMethod','MultipleLines'], axis=1, inplace=True)\n",
    "\n",
    "X.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will perform a grid search for best parameters, this automatically does a cross validation within the training data\n",
    "\n",
    "Also we stratify our data as there are an unbalanced number of 1s and 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scale the data for a better modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(X_train)\n",
    "test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the necessary libraries to perform the GridSearch and RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create out 5 folds for the validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "cv.get_n_splits(train_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform the gridsearch to find out the best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "parameters = {'n_estimators': [80,85,90,100,105,110],\n",
    "              'criterion': ['gini'],\n",
    "              'min_samples_split': [2,3,4],\n",
    "              'min_samples_leaf': [1,2,4,5,6,7],\n",
    "              'max_features': ['auto','sqrt','log2']\n",
    "             }\n",
    "\n",
    "search = GridSearchCV(model, param_grid=parameters, cv=cv, scoring='accuracy', n_jobs = -1, verbose = 5)\n",
    "result = search.fit(train_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters for our case:\n",
    "\n",
    "Best Score: 0.8040957410837188\n",
    "Best Hyperparameters: {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we fit our model with the hyperparameters found previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier(criterion='gini', \n",
    "                             max_features='sqrt', \n",
    "                             min_samples_leaf=4, \n",
    "                             min_samples_split=4, \n",
    "                             n_estimators=100)\n",
    "\n",
    "RFC.fit(train_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict the testing data and print metrics to see how good our model performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = RFC.predict(test_scaled)\n",
    "print('Accuracy: ', accuracy_score(y_test, predictions))\n",
    "print('F1 Score: ', f1_score(y_test, predictions))\n",
    "print('\\n')\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we save our model into a pickle file to use it on the dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'daip5_V2.pkl'\n",
    "pickle.dump(RFC, open(filename, 'wb')) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
